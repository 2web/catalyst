{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "colab": {
   "name": "vanilla-gan-tutorial.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17c73b404fbc457db74612d8431b1198": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_9980ecb1afef47648d64236b11f3e7ff",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_914fa5be61d6466ab60cf90a1b050cdd",
       "IPY_MODEL_d4223ee52e3d4a8093670a02a298896e"
      ]
     }
    },
    "6f8c558f4f7047578de5e15e03e9666e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_68dc071d1b1347d8ae3e47de57d6c8e8",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0f5cad0659bf419c862ce4adf59c74a1",
       "IPY_MODEL_6350d7fb7e89492eb98a56271ae121df"
      ]
     }
    },
    "3de648cb79eb46e5860b3439ba5e2907": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_4125799b99de4c6aaa9ec2d8f0abe42f",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_89c465f73e90480fb2bde1363bcebf5b",
       "IPY_MODEL_380f1c5c91374baabb7cc28ebf3de601"
      ]
     }
    },
    "8721984ceed443578f1ea5f4f26008ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d7278994ed884eb88ec9007fcb307e7c",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d75dece64e0e444790476d8a339dd5e6",
       "IPY_MODEL_96af20b636e343049f73c9ca8d75401a"
      ]
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko_a6FeTnBZg",
    "colab_type": "text"
   },
   "source": [
    "# Vanilla GAN Tutorial\n",
    "\n",
    "Authors: [Artem Zolkin](https://github.com/arquestro)\n",
    "\n",
    "[![Catalyst logo](https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png)](https://github.com/catalyst-team/catalyst)\n",
    "\n",
    "In this tutorial we train simple GANs with the help of Catalyst on MNIST dataset.\n",
    "Our goal here is acquiring generator that can create handwritten digit image from noise vector.\n",
    "\n",
    "For training we can use GanRunner that is provided with catalyst.dl part of the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHuqsaNDnBZt",
    "colab_type": "text"
   },
   "source": [
    "## Requirements\n",
    "For this tutorial we need to have Albumentations and Catalyst 20.2.1 version and higher installed:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dS4oGfAanBZy",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "2e8a6a43-0784-49db-88ec-115143787dc4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581432089237,
     "user_tz": -180,
     "elapsed": 70208,
     "user": {
      "displayName": "Artem Zolkin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mANCYvCC3XaFabYxaPuzeSNW23xB6vMdUJhjld2Tw=s64",
      "userId": "12028082087780039251"
     }
    }
   },
   "source": [
    "# Uncomment the following to install Catalyst\n",
    "!pip install -U catalyst==20.2.1\n",
    "\n",
    "# Uncomment the following to install the latest version of Albumentations\n",
    "!pip install -U albumentations"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V1TBMlm3r5wT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "outputId": "e96599c3-959f-4d6d-8d7b-f02163635d80",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581432162543,
     "user_tz": -180,
     "elapsed": 5588,
     "user": {
      "displayName": "Artem Zolkin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mANCYvCC3XaFabYxaPuzeSNW23xB6vMdUJhjld2Tw=s64",
      "userId": "12028082087780039251"
     }
    }
   },
   "source": [
    "import torch\n",
    "import catalyst\n",
    "import os\n",
    "from catalyst.dl import utils\n",
    "\n",
    "print(f\"torch: {torch.__version__}, catalyst: {catalyst.__version__}\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # \"\" - CPU, \"0\" - 1 GPU\n",
    "SEED = 42\n",
    "utils.set_global_seed(SEED)\n",
    "utils.prepare_cudnn(deterministic=True)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bpC9Z08nBaK",
    "colab_type": "text"
   },
   "source": [
    "## Models For GanRunner(made with PyTorch)\n",
    "First, let's define our discriminator and generator models. We'll just need PyTorch and numpy for that:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "9e5Lu_NVnBaO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cK5QdXMnBac",
    "colab_type": "text"
   },
   "source": [
    "### Generator Model\n",
    "For generator model we'll use is a simple architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "HbsBZLKInBaf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class SimpleGenerator(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_dim=10,\n",
    "        hidden_dim=256,\n",
    "        image_resolution=(28, 28),\n",
    "        channels=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.image_resolution = image_resolution\n",
    "        self.channels = channels\n",
    "\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(noise_dim, hidden_dim), torch.nn.LeakyReLU(0.05),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.LeakyReLU(0.05),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.LeakyReLU(0.05),\n",
    "            torch.nn.Linear(hidden_dim, numpy.prod(image_resolution)), torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.reshape(x.size(0), self.channels, *self.image_resolution)\n",
    "        return x"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H72GGCcNnBas",
    "colab_type": "text"
   },
   "source": [
    "### Discriminator Model\n",
    "\n",
    "And for discriminator model we'll use this architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "rlgS84wunBav",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class SimpleDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, image_resolution=(28, 28), channels=1, hidden_dim=100):\n",
    "        super().__init__()\n",
    "        self.image_resolution = image_resolution\n",
    "        self.channels = channels\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(channels * numpy.prod(image_resolution), hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.05), torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.05), torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.05), torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.05), torch.nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x.reshape(x.size(0), -1))\n",
    "        return x"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNYRB6TznBa4",
    "colab_type": "text"
   },
   "source": [
    "### Initializing And Combining models\n",
    "\n",
    "And we need to initialize our models and combine them into a dictionary.\n",
    "Pay attention to discriminator_key and generator_key variables, we'll need them later. Don't forget about the noise dimension parameter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "1P6rnf_QnBa8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "noise_dim = 16\n",
    "discriminator_key = 'discriminator'\n",
    "discriminator = SimpleDiscriminator()\n",
    "generator_key = 'generator'\n",
    "generator = SimpleGenerator(noise_dim=noise_dim)\n",
    "model = torch.nn.ModuleDict({\n",
    "    discriminator_key: discriminator,\n",
    "    generator_key: generator,\n",
    "})"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OilVu0QMnBbM",
    "colab_type": "text"
   },
   "source": [
    "## Datasets and Data Loaders\n",
    "\n",
    "Second, we define datasets and data loaders that GanRunner will use for train and validation. We'll use torchvision library to retrieve MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "uveNtf8znBbR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SYLyk2dnBbX",
    "colab_type": "text"
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSwWNLYDnBbZ",
    "colab_type": "text"
   },
   "source": [
    "#### Data Transforms\n",
    "\n",
    "We need to provide our datasets with proper transforms. To deliver proper data too our GanRunner we have to add additional scalar and noise tensor with transforms. For these purposes let's use Albumentations transforms and make custom ones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "r2WSmQIbnBbb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Custom transforms are from \"mnist-gans\" example, transforms.py\n",
    "from typing import Tuple, Union\n",
    "from albumentations.core.transforms_interface import BasicTransform, ImageOnlyTransform\n",
    "\n",
    "class AsImage(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1.0):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        if img.ndim == 2:\n",
    "            return np.expand_dims(img, axis=-1)\n",
    "        return img\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class AdditionalValue(BasicTransform):\n",
    "    def __init__(self, output_key: str = None, **kwargs):\n",
    "        self.name = \"AdditionalValue\"\n",
    "        self.output_key = output_key\n",
    "\n",
    "    def __call__(self, force_apply=False, **dict_):\n",
    "        assert self.output_key not in dict_, \\\n",
    "            \"Output key is supposed not to be present in dict\"\n",
    "        dict_[self.output_key] = self._compute_output(dict_)\n",
    "        return dict_\n",
    "    \n",
    "    def _compute_output(self, dict_):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class AdditionalNoiseTensor(AdditionalValue):\n",
    "    def __init__(self, tensor_size: Tuple[int, ...], output_key: str = None):\n",
    "        super().__init__(output_key)\n",
    "        self.tensor_size = tensor_size\n",
    "\n",
    "    def _compute_output(self, dict_):\n",
    "        return torch.randn(self.tensor_size)\n",
    "\n",
    "    \n",
    "class AdditionalScalar(AdditionalValue):\n",
    "    def __init__(self, value: Union[int, float], output_key: str = None):\n",
    "        super().__init__(output_key)\n",
    "        self.value = value\n",
    "\n",
    "    def _compute_output(self, dict_):\n",
    "        return torch.tensor([self.value])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "O4c59zgdnBbg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from albumentations import Compose\n",
    "from albumentations.augmentations.transforms import Normalize\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "noise_input = \"noise\"\n",
    "real_targets = \"real_targets\"\n",
    "fake_targets = \"fake_targets\"\n",
    "data_transforms = Compose(transforms=[\n",
    "    AsImage(),\n",
    "    Normalize(mean=0.5, std=0.5),\n",
    "    ToTensorV2(),\n",
    "    AdditionalNoiseTensor(tensor_size=[noise_dim], output_key=noise_input),\n",
    "    AdditionalScalar(value=1.0, output_key=real_targets),\n",
    "    AdditionalScalar(value=0.0, output_key=fake_targets),\n",
    "])\n",
    "# Workaround \"wrapper\" to deliver transforms to torchvision dataset superclass\n",
    "def transform(dict_):\n",
    "    return data_transforms(**dict_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e16NVVwnBbm",
    "colab_type": "text"
   },
   "source": [
    "#### Initialize Datasets\n",
    "Let's wrap up the torchvision MNIST dataset and define datasets for future use in data loaders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "KFc6N7pcnBbn",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221,
     "referenced_widgets": [
      "17c73b404fbc457db74612d8431b1198",
      "6f8c558f4f7047578de5e15e03e9666e",
      "3de648cb79eb46e5860b3439ba5e2907",
      "8721984ceed443578f1ea5f4f26008ce"
     ]
    },
    "outputId": "db2bcbcd-1ea4-4589-ac4d-20c671a15def",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581432199186,
     "user_tz": -180,
     "elapsed": 24731,
     "user": {
      "displayName": "Artem Zolkin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mANCYvCC3XaFabYxaPuzeSNW23xB6vMdUJhjld2Tw=s64",
      "userId": "12028082087780039251"
     }
    }
   },
   "source": [
    "class MNIST(torchvision.datasets.MNIST):\n",
    "    \"\"\"\n",
    "    MNIST Dataset with key_value __get_item__ output\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "        image_key=\"image\",\n",
    "        target_key=\"target\"\n",
    "    ):\n",
    "        super().__init__(root, train, transform, target_transform, download)\n",
    "        self.image_key = image_key\n",
    "        self.target_key = target_key\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"Get dataset element\"\"\"\n",
    "        image, target = self.data[index], self.targets[index]\n",
    "        dict_ = {\n",
    "            self.image_key: image,\n",
    "            self.target_key: target,\n",
    "        }\n",
    "        if self.transform is not None:\n",
    "            dict_ = self.transform(dict_)\n",
    "        return dict_\n",
    "\n",
    "\n",
    "train_dataset_real = MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "valid_dataset = MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "datasets = {\n",
    "    \"train\": train_dataset_real,\n",
    "    \"valid\": valid_dataset,\n",
    "}"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpYY8CWSnBbx",
    "colab_type": "text"
   },
   "source": [
    "### Defining loaders\n",
    "\n",
    "Notice, that we need to provide our GanRunner only with dataloaders, no datasets in the input further, they're already in data loaders.\n",
    "\n",
    "Pay attention, that loaders name with train datasets must begin with \"train\" to be picked up properly by Runner functionality further. Same rule for validation data loader naming."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "-i4ZHq2rnBbz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "batch_size = 64\n",
    "train_loader_real = DataLoader(train_dataset_real, batch_size=batch_size)\n",
    "valid_loader_real = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "loaders = {\n",
    "    \"train\": train_loader_real,\n",
    "    \"valid\": valid_loader_real,\n",
    "}\n",
    "loaders = OrderedDict(loaders)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahfVVDQynBb4",
    "colab_type": "text"
   },
   "source": [
    "## Criterion\n",
    "Let's define the criterion for our GanRunner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0YGwLR5tnBb5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "\n",
    "criterion = BCEWithLogitsLoss()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC792lxnnBb9",
    "colab_type": "text"
   },
   "source": [
    "## Optimizers\n",
    "Next we define the optimizers for each of our models, discriminator and generator."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jP555T5CnBcF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "lr = 0.0002\n",
    "discriminator_optimizer = Adam(discriminator.parameters(), lr=lr)\n",
    "generator_optimizer = Adam(generator.parameters(), lr=lr)\n",
    "optimizer = {\n",
    "    discriminator_key: discriminator_optimizer,\n",
    "    generator_key: generator_optimizer,\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9m0cyywOnBcJ",
    "colab_type": "text"
   },
   "source": [
    "## Runner state key-value arguments\n",
    "The following dictionary items \"phase\" and \"num\" are needed to get PhaseManagerCallback working properly in the GanRunner. And we need to include the noise dimensions to provide runner with it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o4pxysCdnBcL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "state_kwargs = {\n",
    "    \"discriminator_train_phase\": \"discriminator_train\",\n",
    "    \"discriminator_train_num\": 1,\n",
    "    \"generator_train_phase\": \"generator_train\",\n",
    "    \"generator_train_num\": 1,\n",
    "    \"noise_dim\": noise_dim,\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAm_HP-unBcP",
    "colab_type": "text"
   },
   "source": [
    "## Callbacks\n",
    "Following callbacks include loss definition, optimizers, logging. Then for GanRunner to work properly we have to define what callbacks should be converted to PhaseBatchWrapperCallback later in GanExperiment. GanExperiment is ran by GanRunner during training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7Xvgb534nBcR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from catalyst.dl.callbacks import CriterionAggregatorCallback\n",
    "from catalyst.dl import OptimizerCallback, CriterionCallback\n",
    "\n",
    "discriminator_loss_key = \"loss_d\"\n",
    "generator_loss_key = \"loss_g\"\n",
    "from catalyst.dl import TensorboardLogger\n",
    "callbacks = OrderedDict({\n",
    "    \"loss_d_real\": CriterionCallback(\n",
    "        input_key=\"real_targets\", \n",
    "        output_key=\"real_logits\", \n",
    "        prefix=\"loss_d_real\"\n",
    "    ),\n",
    "    \"loss_d_fake\": CriterionCallback(\n",
    "        input_key=\"fake_targets\", \n",
    "        output_key=\"fake_logits\", \n",
    "        prefix=\"loss_d_fake\"\n",
    "    ),\n",
    "    discriminator_loss_key: CriterionAggregatorCallback(\n",
    "        loss_keys=[\"loss_d_real\", \"loss_d_fake\"],\n",
    "        loss_aggregate_fn=\"mean\", prefix=discriminator_loss_key\n",
    "    ),\n",
    "    generator_loss_key: CriterionCallback(\n",
    "        input_key=\"real_targets\", \n",
    "        output_key=\"fake_logits\",\n",
    "        prefix=generator_loss_key\n",
    "    ),\n",
    "    \"optim_d\": OptimizerCallback(\n",
    "        loss_key=discriminator_loss_key,\n",
    "        optimizer_key=discriminator_key\n",
    "    ),\n",
    "    \"optim_g\": OptimizerCallback(\n",
    "        loss_key=generator_loss_key,\n",
    "        optimizer_key=generator_key\n",
    "    ),\n",
    "    \"tensorboard\": TensorboardLogger(),\n",
    "})\n",
    "# Preparation for callback wrapping. Wrapping is done later in GanExperiment, which is run by GanRunner\n",
    "discriminator_phase_callbacks = [\"loss_d_real\", \"loss_d_fake\", discriminator_loss_key, \"optim_d\"]\n",
    "generator_phase_callbacks = [generator_loss_key, \"optim_g\"]\n",
    "phase2callbacks = {\n",
    "    state_kwargs[\"discriminator_train_phase\"]: discriminator_phase_callbacks,\n",
    "    state_kwargs[\"generator_train_phase\"]: generator_phase_callbacks,\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5rMPFeUnBcX",
    "colab_type": "text"
   },
   "source": [
    "## GanRunner\n",
    "Define other training parameters and initialize GanRunner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ANvUVLv2nBcZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "logdir = \"./logs\"\n",
    "num_epochs = 100\n",
    "main_metric = generator_loss_key\n",
    "verbose = True\n",
    "check = False"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "eLp5MHBbnBcd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from catalyst.dl.runner import GanRunner\n",
    "\n",
    "real_data_key = \"image\"\n",
    "runner = GanRunner(\n",
    "    data_input_key=real_data_key,\n",
    "    discriminator_model_key=discriminator_key,\n",
    "    generator_model_key=generator_key,\n",
    ")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9FrBUUEnBci",
    "colab_type": "text"
   },
   "source": [
    "## Start the GAN training\n",
    "Finally, let's run the training!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "CQZtjP2MnBcj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "d5affc0e-caf5-47b5-8390-567edcd427b4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581433744867,
     "user_tz": -180,
     "elapsed": 1566125,
     "user": {
      "displayName": "Artem Zolkin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mANCYvCC3XaFabYxaPuzeSNW23xB6vMdUJhjld2Tw=s64",
      "userId": "12028082087780039251"
     }
    }
   },
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    logdir=logdir,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    main_metric=main_metric,\n",
    "    state_kwargs=state_kwargs,\n",
    "    phase2callbacks=phase2callbacks,\n",
    "    verbose=verbose,\n",
    "    check=check,\n",
    ")"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "031ABMNxnBcr",
    "colab_type": "text"
   },
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0rL5xUh_nBcs",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "outputId": "36ca7ff0-1385-4fa8-8457-30df0ffb33dc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581433859910,
     "user_tz": -180,
     "elapsed": 1075,
     "user": {
      "displayName": "Artem Zolkin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mANCYvCC3XaFabYxaPuzeSNW23xB6vMdUJhjld2Tw=s64",
      "userId": "12028082087780039251"
     }
    }
   },
   "source": [
    "# In a courtesy of Caffe's filter visualization example\n",
    "# http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow_grid(data, height=None, width=None, normalize=False, padsize=1, padval=0):\n",
    "    '''\n",
    "    Take an array of shape (N, H, W) or (N, H, W, C)\n",
    "    and visualize each (H, W) image in a grid style (height x width).\n",
    "    '''\n",
    "    if normalize:\n",
    "        data -= data.min()\n",
    "        data /= data.max()\n",
    "\n",
    "    N = data.shape[0]\n",
    "    if height is None:\n",
    "        if width is None:\n",
    "            height = int(np.ceil(np.sqrt(N)))\n",
    "        else:\n",
    "            height = int(np.ceil( N / float(width) ))\n",
    "\n",
    "    if width is None:\n",
    "        width = int(np.ceil( N / float(height) ))\n",
    "\n",
    "    assert height * width >= N\n",
    "\n",
    "    # append padding\n",
    "    padding = ((0, (width*height) - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "\n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((height, width) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((height * data.shape[1], width * data.shape[3]) + data.shape[4:])\n",
    "\n",
    "    plt.imshow(data)\n",
    "\n",
    "\n",
    "noise_sample = torch.randn((25, noise_dim)).to('cuda:0')\n",
    "result = runner.model[generator_key].forward(noise_sample)\n",
    "print(result.shape)\n",
    "result = result.permute((0, 2, 3, 1)).cpu().detach().numpy()\n",
    "result = numpy.repeat(result, repeats=3,axis=3)\n",
    "imshow_grid(result)"
   ],
   "execution_count": 28,
   "outputs": []
  }
 ]
}